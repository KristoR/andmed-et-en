"""Generate candidate term reports from extraction results."""

from __future__ import annotations

import datetime
import logging
from pathlib import Path

import yaml

from .term_extractor import TermMatch

logger = logging.getLogger(__name__)


def generate_candidate_yaml(
    missing_terms: list[TermMatch],
    nlp_novel_terms: list[TermMatch],
    output_path: Path,
) -> None:
    """Write candidate terms to a YAML file."""
    entries: list[dict] = []

    for match in missing_terms:
        entry: dict = {
            "en": match.en,
            "confidence": match.confidence,
            "frequency": match.frequency,
            "source": match.source,
            "category": match.category,
        }
        if match.et_hints:
            entry["et_hints"] = match.et_hints
        if match.thesis_refs:
            entry["sample_theses"] = match.thesis_refs
        entries.append(entry)

    for match in nlp_novel_terms:
        entry = {
            "en": match.en,
            "confidence": match.confidence,
            "frequency": match.frequency,
            "source": match.source,
        }
        if match.thesis_refs:
            entry["sample_theses"] = match.thesis_refs
        entries.append(entry)

    header = (
        f"# Auto-generated by fetch_theses.py on {datetime.date.today().isoformat()}\n"
        "# Candidate terms NOT yet in data/terms.yml\n"
        "# Review these and add relevant ones to data/terms.yml\n\n"
    )

    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        f.write(header)
        yaml.dump(entries, f, allow_unicode=True, default_flow_style=False, sort_keys=False)

    logger.info("Wrote %d candidate terms to %s", len(entries), output_path)


def print_summary(
    missing_terms: list[TermMatch],
    confirmed_terms: list[TermMatch],
    nlp_novel_terms: list[TermMatch],
    thesis_counts: dict[str, int],
    from_date: str,
    until_date: str,
) -> None:
    """Print a human-readable summary to stdout."""
    total = sum(thesis_counts.values())
    counts_str = ", ".join(f"{k.upper()}: {v}" for k, v in sorted(thesis_counts.items()))

    print()
    print("=" * 60)
    print("  Thesis Term Discovery Report")
    print("=" * 60)
    print()
    print(f"  Theses analyzed: {total} ({counts_str})")
    print(f"  Date range: {from_date} to {until_date}")
    print()

    # High confidence (curated, missing from glossary)
    print(f"  HIGH CONFIDENCE (curated list match, not in glossary): {len(missing_terms)} terms")
    if missing_terms:
        for match in missing_terms[:30]:
            hints = f" (ET: {', '.join(match.et_hints)})" if match.et_hints else ""
            print(f"    {match.en} ({match.frequency} mentions){hints}")
        if len(missing_terms) > 30:
            print(f"    ... and {len(missing_terms) - 30} more")
    print()

    # Medium confidence (NLP-discovered)
    print(f"  MEDIUM CONFIDENCE (NLP-discovered, not in glossary): {len(nlp_novel_terms)} terms")
    if nlp_novel_terms:
        for match in nlp_novel_terms[:20]:
            print(f"    {match.en} ({match.frequency} mentions)")
        if len(nlp_novel_terms) > 20:
            print(f"    ... and {len(nlp_novel_terms) - 20} more")
    print()

    # Confirmed (already in glossary)
    print(f"  ALREADY IN GLOSSARY (confirmed): {len(confirmed_terms)} terms")
    if confirmed_terms:
        for match in confirmed_terms:
            print(f"    {match.en}: {match.frequency} mentions")
    print()
    print("=" * 60)
    print()
